{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ff74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd73108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDatasetSingular(Dataset):\n",
    "    def __init__(self, image_paths, crop_size = 512, gaussian_sigma = 50, add_noise = True):\n",
    "        self.image_paths = image_paths\n",
    "        self.crop_size = crop_size\n",
    "        self.gaussian_sigma = gaussian_sigma\n",
    "        self.add_noise = add_noise\n",
    "        \n",
    "        if crop_size is None:\n",
    "            transforms_list = []\n",
    "        else:\n",
    "            # Random crop followed by either a random horizontal flip or a random vertical flip\n",
    "            transforms_list = [transforms.RandomCrop(crop_size), \n",
    "                               transforms.RandomChoice([transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip()])]\n",
    "            \n",
    "        transforms_list += [transforms.ToTensor()]\n",
    "        self.transforms = transforms.Compose(transforms_list)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_image = Image.open(self.image_paths[idx])\n",
    "        transformed_real = self.transforms(real_image)\n",
    "        noisy_image = transformed_real\n",
    "        \n",
    "        if self.add_noise:\n",
    "            noisy_image += torch.randn_like(transformed_real) * self.gaussian_sigma/255.0\n",
    "            noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "        \n",
    "        return transformed_real, noisy_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06263de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalResidualBlock(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(ConvolutionalResidualBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_channels = 64\n",
    "        self.padding = int((self.kernel_size-1)/2)\n",
    "        self.conv_1 = nn.Conv2d(self.num_channels, self.num_channels, kernel_size = self.kernel_size, padding = self.padding, bias = False)\n",
    "        self.conv_2 = nn.Conv2d(self.num_channels, self.num_channels, kernel_size = self.kernel_size, padding = self.padding, bias = False)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_2(out)\n",
    "        out = out + identity # Residual Connection\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd39fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepConvolutionalModel(nn.Module):\n",
    "    def __init__(self, depth = 17, kernel_size = 3):\n",
    "        super(DeepConvolutionalModel, self).__init__()\n",
    "        self.layers = []\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depth = depth\n",
    "        self.padding = int((self.kernel_size - 1)/2)\n",
    "        self.num_channels = 64\n",
    "        self.layers.append(nn.Conv2d(3, self.num_channels, kernel_size = self.kernel_size, padding = self.padding, bias = False))\n",
    "        self.layers.append(nn.ReLU(inplace = True))\n",
    "        \n",
    "\n",
    "        # Stack convolutional blocks with residual connections\n",
    "        for _ in range(depth-2):\n",
    "            self.layers.append(ConvolutionalResidualBlock(self.kernel_size))\n",
    "            \n",
    "        self.layers.append(nn.Conv2d(self.num_channels, 3, kernel_size = self.kernel_size, padding = self.padding, bias = False))\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "        self._initialize_weights() \n",
    "        \n",
    "    \n",
    "    def forward(self, noisy_image):\n",
    "        residual = self.model(noisy_image)\n",
    "        return noisy_image - residual\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                \n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6f1477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "\n",
    "def validation_step(model, dataloader, refining_steps = 1):\n",
    "    real_psnr_aggregate = []\n",
    "    denoised_psnr_aggregate = []\n",
    "    real_ssim_aggregate = []\n",
    "    denoised_ssim_aggregate = []\n",
    "    loss_vals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()   # Switches model to evaluation mode (no gradient computation)\n",
    "        for data_bunch in dataloader:\n",
    "            real, noisy = data_bunch\n",
    "#             real, noisy = real.cuda(), noisy.cuda()\n",
    "            current_noisy = noisy\n",
    "            for _ in range(refining_steps):\n",
    "                denoised_image = model(current_noisy)\n",
    "                loss = criterion(denoised_image, real)\n",
    "                loss = loss.div_(2)\n",
    "                current_noisy = denoised_image\n",
    "\n",
    "            loss_vals.append(loss.item())\n",
    "            \n",
    "            # Convert the PyTorch tensors representing real, noisy, and denoised \n",
    "            # images to NumPy arrays and reshape them to the expected format (channels-last) for PSNR and SSIM computations.\n",
    "            \n",
    "            real_numpy, noisy_numpy, denoised_numpy = [img.cpu().numpy().transpose(0, 2, 3, 1) for img in [real, noisy, denoised_image]]\n",
    "\n",
    "            for idx in range(real_numpy.shape[0]):\n",
    "                real, noisy, denoised = real_numpy[idx], noisy_numpy[idx], denoised_numpy[idx]\n",
    "                real_psnr, denoised_psnr = compare_psnr(real, noisy), compare_psnr(real, denoised)\n",
    "                real_ssim, denoised_ssim = compare_ssim(real, noisy, multichannel=True), compare_ssim(real, denoised, multichannel=True)\n",
    "                real_ssim_aggregate.append(real_ssim)\n",
    "                denoised_ssim_aggregate.append(denoised_ssim)\n",
    "                real_psnr_aggregate.append(real_psnr)\n",
    "                denoised_psnr_aggregate.append(denoised_psnr)\n",
    "        model = model.train()\n",
    "\n",
    "    avg_real_psnr, avg_denoised_psnr, avg_ssim_real, avg_ssim_denoised, avg_loss = np.mean(real_psnr_aggregate), np.mean(denoised_psnr_aggregate), np.mean(real_ssim_aggregate), np.mean(denoised_ssim_aggregate), np.mean(loss_vals)\n",
    "    return avg_real_psnr, avg_denoised_psnr, avg_ssim_real, avg_ssim_denoised, avg_loss\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bbf5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b33f8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = glob.glob(\"../Simple-Datasets/DIV2K-Dataset/DIV2K_train_HR/DIV2K_train_HR/*.png\")\n",
    "val_image_paths = glob.glob(\"../Simple-Datasets/DIV2K-Dataset/DIV2K_valid_HR/DIV2K_valid_HR/*.png\")\n",
    "\n",
    "train_image_paths, val_image_paths = train_test_split(train_image_paths + val_image_paths, test_size = 0.2, random_state = 42)\n",
    "cbs_image_paths = glob.glob(\"../Simple-Datasets/CBSD68-Dataset/CBSD68/original/*.jpg\")\n",
    "\n",
    "train_dataset = DenoisingDatasetSingular(train_image_paths, crop_size = 128, gaussian_sigma = 50)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32, num_workers = 0)\n",
    "\n",
    "test_dataset = DenoisingDatasetSingular(val_image_paths, crop_size = 128, gaussian_sigma = 50)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 32, num_workers = 0)\n",
    "\n",
    "cbs_dataset = DenoisingDatasetSingular(cbs_image_paths, crop_size = 256, gaussian_sigma = 50)\n",
    "cbs_dataloader = DataLoader(cbs_dataset, batch_size = 16, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75aa501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepConvolutionalModel(depth = 3, kernel_size = 3)\n",
    "# model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 3)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da7d2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepConvolutionalModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvolutionalResidualBlock(\n",
      "      (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28025267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3b5b632b3449be875dda76c0ad90ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:31: UserWarning: DEPRECATED: skimage.measure.compare_psnr has been moved to skimage.metrics.peak_signal_noise_ratio. It will be removed from skimage.measure in version 0.18.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "im_true has intensity values outside the range expected for its data type.  Please manually specify the data_range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-9ce17a577b24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# total_iterations = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0miteration_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mavg_real_psnr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_denoised_psnr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_ssim_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_ssim_denoised\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mvalidation_real_psnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_real_psnr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mvalidation_denoised_psnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_denoised_psnr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-b3792c4cae9f>\u001b[0m in \u001b[0;36mvalidation_step\u001b[1;34m(model, dataloader, refining_steps)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_numpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenoised\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_numpy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoisy_numpy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenoised_numpy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0mreal_psnr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenoised_psnr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenoised\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[0mreal_ssim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenoised_ssim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenoised\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mreal_ssim_aggregate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_ssim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\skimage\\measure\\simple_metrics.py\u001b[0m in \u001b[0;36mcompare_psnr\u001b[1;34m(im_true, im_test, data_range)\u001b[0m\n\u001b[0;32m     62\u001b[0m          \u001b[1;34m'skimage.metrics.peak_signal_noise_ratio. It will be removed from '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m          'skimage.measure in version 0.18.', stacklevel=2)\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpeak_signal_noise_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\skimage\\metrics\\simple_metrics.py\u001b[0m in \u001b[0;36mpeak_signal_noise_ratio\u001b[1;34m(image_true, image_test, data_range)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrue_max\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mdmax\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtrue_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mdmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             raise ValueError(\n\u001b[1;32m--> 149\u001b[1;33m                 \u001b[1;34m\"im_true has intensity values outside the range expected for \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                 \"its data type.  Please manually specify the data_range\")\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrue_min\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: im_true has intensity values outside the range expected for its data type.  Please manually specify the data_range"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "num_epochs = 10\n",
    "validation_iter = 50\n",
    "total_iterations = 0\n",
    "\n",
    "training_loss_vals = []\n",
    "\n",
    "validation_real_psnr = []\n",
    "validation_denoised_psnr = []\n",
    "validation_ssim_real = []\n",
    "validation_ssim_denoised = []\n",
    "validation_loss = []\n",
    "iteration_list = []\n",
    "\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "\n",
    "    scheduler.step(epoch)\n",
    "\n",
    "    for data_bunch in train_dataloader:\n",
    "\n",
    "        if total_iterations%validation_iter == 0:\n",
    "            # total_iterations = 0\n",
    "            iteration_list.append(total_iterations)\n",
    "            avg_real_psnr, avg_denoised_psnr, avg_ssim_real, avg_ssim_denoised, avg_loss = validation_step(model, test_dataloader)  \n",
    "            validation_real_psnr.append(avg_real_psnr)\n",
    "            validation_denoised_psnr.append(avg_denoised_psnr)\n",
    "            validation_ssim_real.append(avg_ssim_real)\n",
    "            validation_ssim_denoised.append(avg_ssim_denoised)\n",
    "            validation_loss.append(avg_loss)\n",
    "\n",
    "        real, noisy = data_bunch\n",
    "#         real, noisy = real.cuda(), noisy.cuda()\n",
    "        denoised_image = model(noisy)\n",
    "\n",
    "        loss = criterion(denoised_image, real)\n",
    "        loss = loss.div_(2)\n",
    "\n",
    "        training_loss_vals.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_iterations += 1\n",
    "\n",
    "avg_real_psnr, avg_denoised_psnr, avg_ssim_real, avg_ssim_denoised, avg_loss = validation_step(model, test_dataloader)\n",
    "validation_real_psnr.append(avg_real_psnr)\n",
    "validation_denoised_psnr.append(avg_denoised_psnr)\n",
    "validation_ssim_real.append(avg_ssim_real)\n",
    "validation_ssim_denoised.append(avg_ssim_denoised)\n",
    "validation_loss.append(avg_loss)\n",
    "iteration_list.append(total_iterations)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3423c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_loss_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-71a49261ef0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loss_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss (Log scale)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_loss_vals' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.log(training_loss_vals), label='Training loss')\n",
    "plt.gca().set_ylabel('Loss (Log scale)')\n",
    "plt.gca().set_xlabel('Iterations')\n",
    "plot_data = validation_loss\n",
    "plt.plot(iteration_list, np.log(plot_data), label='Validation loss')\n",
    "plt.title(\"Loss vs Iterations (Sigma = 50)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_vs_iterations_sigma_50.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6922500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1b0a990d7f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28953c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
